{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d373d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import extract_function as ef\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d1f9d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"/home/ak47/AI_proj/Data/\"\n",
    "entries = Path(url)\n",
    "labels=[]\n",
    "for entry in entries.iterdir():\n",
    "    labels.append(str(entry.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "be9d91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio=[]\n",
    "for label in labels:\n",
    "    file= Path(url+label)\n",
    "    for f in file.iterdir():\n",
    "        audio.append((url+label+\"/\"+str(f.name)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1e1e62fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "speakers=[]\n",
    "for file_path in audio:\n",
    "    speakers.append(tf.strings.split(file_path, '/')[-2])\n",
    "\n",
    "speaker_encoder = preprocessing.LabelEncoder()\n",
    "speaker_idx = speaker_encoder.fit_transform([bytes.decode(s.numpy()) for s in speakers])\n",
    "encoded_speaker_ds = tf.data.Dataset.from_tensor_slices(speaker_idx)\n",
    "\n",
    "unique_speakers = len(speaker_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "36178363",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_f=[]\n",
    "for i in range(len(audio)):\n",
    "    wave, sample_rate = librosa.load(audio[i], mono=True, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(wave, sample_rate)\n",
    "    mfcc = mfcc[:, :196]\n",
    "    pad_width = 196 - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    mfcc = tf.convert_to_tensor(mfcc)\n",
    "    mfcc = tf.expand_dims(mfcc, 2)\n",
    "    mfcc_f.append(mfcc)\n",
    "audio_ds=tf.data.Dataset.from_tensor_slices(mfcc_f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0e4e312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_labeled_ds = tf.data.Dataset.zip((audio_ds, encoded_speaker_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8a9acc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, speaker in complete_labeled_ds.take(1):\n",
    "    input_shape = a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c7ddf4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples: 1147\n",
      "training samples: 1032\n",
      "validation samples: 57\n",
      "test samples: 58\n"
     ]
    }
   ],
   "source": [
    "labeled_ds = complete_labeled_ds\n",
    "data_size = len(labeled_ds)\n",
    "train_size = int(data_size * 0.9)\n",
    "val_size = int(data_size * 0.05)\n",
    "test_size = data_size - train_size - val_size\n",
    "print('all samples: {}'.format(data_size))\n",
    "print('training samples: {}'.format(train_size))\n",
    "print('validation samples: {}'.format(val_size))\n",
    "print('test samples: {}'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "142b089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batched datasets\n",
    "batch_size = 516\n",
    "labeled_ds = labeled_ds.shuffle(data_size, seed=42)\n",
    "train_ds = labeled_ds.take(train_size).shuffle(1000).batch(batch_size).prefetch(1)\n",
    "val_ds = labeled_ds.skip(train_size).take(val_size).batch(batch_size).prefetch(1)\n",
    "test_ds = labeled_ds.skip(train_size + val_size).take(test_size).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4eafc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    dropout_rate = .25\n",
    "    regularazation = 0.001\n",
    "    audio_input = keras.layers.Input(shape=input_shape)\n",
    "    conv1 = keras.layers.Conv2D(16, kernel_size=(3, 3), padding='same',\n",
    "                               activation='relu', input_shape=input_shape)(audio_input)\n",
    "    maxpool1 = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(conv1)\n",
    "    batch1 = keras.layers.BatchNormalization()(maxpool1)\n",
    "    conv2 = keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same',\n",
    "                               activation='relu', input_shape=input_shape)(batch1)\n",
    "    maxpool2 = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(conv2)\n",
    "    batch2 = keras.layers.BatchNormalization()(maxpool2)\n",
    "    conv3 = keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same', \n",
    "                activation='relu')(batch2)\n",
    "    maxpool3 = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(conv3)\n",
    "    batch3 = keras.layers.BatchNormalization()(maxpool3)\n",
    "    flt = keras.layers.Flatten()(batch3)\n",
    "    drp1 = keras.layers.Dropout(dropout_rate)(flt)\n",
    "    dense1 = keras.layers.Dense(unique_speakers * 2, activation='relu',\n",
    "                kernel_regularizer=keras.regularizers.l2(regularazation))(drp1)\n",
    "    drp2 = keras.layers.Dropout(dropout_rate)(dense1)\n",
    "    output = keras.layers.Dense(unique_speakers, activation='softmax', name='speaker')(drp2)\n",
    "    model = keras.Model(inputs=audio_input, outputs=output)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e6ad9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "train_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2a85e23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 20, 196, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 20, 196, 16)       160       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 10, 98, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 10, 98, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 10, 98, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 5, 49, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 5, 49, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 5, 49, 64)         18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 2, 24, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 2, 24, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 18)                55314     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 18)                0         \n",
      "                                                                 \n",
      " speaker (Dense)             (None, 9)                 171       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,229\n",
      "Trainable params: 79,005\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c3a49b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 215ms/step - loss: 2.4911 - acc: 0.1250 - val_loss: 2.2433 - val_acc: 0.2281\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.9124 - acc: 0.2897 - val_loss: 2.0794 - val_acc: 0.1754\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.7203 - acc: 0.3314 - val_loss: 1.9949 - val_acc: 0.3509\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.5246 - acc: 0.4506 - val_loss: 2.2653 - val_acc: 0.2982\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.3915 - acc: 0.4952 - val_loss: 2.7035 - val_acc: 0.1754\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.3059 - acc: 0.5262 - val_loss: 2.5141 - val_acc: 0.2982\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1532 - acc: 0.5872 - val_loss: 3.6339 - val_acc: 0.1228\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0882 - acc: 0.6047 - val_loss: 4.3881 - val_acc: 0.1930\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0353 - acc: 0.6105 - val_loss: 5.0756 - val_acc: 0.1404\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.9609 - acc: 0.6492 - val_loss: 6.0582 - val_acc: 0.0877\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.8636 - acc: 0.6822 - val_loss: 5.9788 - val_acc: 0.0702\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8021 - acc: 0.7122 - val_loss: 5.7328 - val_acc: 0.1754\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7787 - acc: 0.7209 - val_loss: 6.6618 - val_acc: 0.0175\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.7241 - acc: 0.7258 - val_loss: 5.4789 - val_acc: 0.0877\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6560 - acc: 0.7791 - val_loss: 6.1284 - val_acc: 0.1404\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6527 - acc: 0.7539 - val_loss: 6.0380 - val_acc: 0.1404\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5927 - acc: 0.7829 - val_loss: 5.5236 - val_acc: 0.2105\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5507 - acc: 0.7975 - val_loss: 4.7939 - val_acc: 0.1404\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5093 - acc: 0.8188 - val_loss: 4.6900 - val_acc: 0.2281\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4883 - acc: 0.8130 - val_loss: 5.2361 - val_acc: 0.1228\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4682 - acc: 0.8314 - val_loss: 4.8965 - val_acc: 0.1579\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4962 - acc: 0.8043 - val_loss: 4.3453 - val_acc: 0.2281\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4782 - acc: 0.8101 - val_loss: 4.2230 - val_acc: 0.2456\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4292 - acc: 0.8314 - val_loss: 4.4839 - val_acc: 0.1930\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4042 - acc: 0.8527 - val_loss: 4.0652 - val_acc: 0.2456\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3588 - acc: 0.8692 - val_loss: 3.2626 - val_acc: 0.3333\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3576 - acc: 0.8653 - val_loss: 3.2213 - val_acc: 0.2281\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3620 - acc: 0.8576 - val_loss: 3.7080 - val_acc: 0.2807\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3461 - acc: 0.8750 - val_loss: 4.1445 - val_acc: 0.1404\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3448 - acc: 0.8614 - val_loss: 3.9845 - val_acc: 0.1579\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3258 - acc: 0.8876 - val_loss: 3.0895 - val_acc: 0.2632\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2832 - acc: 0.9089 - val_loss: 2.9409 - val_acc: 0.2281\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3030 - acc: 0.8992 - val_loss: 2.7658 - val_acc: 0.2632\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2470 - acc: 0.9186 - val_loss: 2.8023 - val_acc: 0.2281\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2824 - acc: 0.9118 - val_loss: 2.6422 - val_acc: 0.2982\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2528 - acc: 0.9186 - val_loss: 2.9464 - val_acc: 0.1404\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2515 - acc: 0.9186 - val_loss: 2.2660 - val_acc: 0.1930\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2411 - acc: 0.9167 - val_loss: 2.1583 - val_acc: 0.2105\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2232 - acc: 0.9273 - val_loss: 2.3435 - val_acc: 0.2632\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2134 - acc: 0.9390 - val_loss: 2.2745 - val_acc: 0.2105\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2089 - acc: 0.9360 - val_loss: 2.2687 - val_acc: 0.2632\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.1894 - acc: 0.9438 - val_loss: 1.9733 - val_acc: 0.2632\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2041 - acc: 0.9360 - val_loss: 1.9903 - val_acc: 0.3158\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1914 - acc: 0.9438 - val_loss: 1.8421 - val_acc: 0.3333\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1725 - acc: 0.9486 - val_loss: 1.7596 - val_acc: 0.3684\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1703 - acc: 0.9554 - val_loss: 1.8943 - val_acc: 0.4035\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.1767 - acc: 0.9496 - val_loss: 1.5128 - val_acc: 0.4561\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1535 - acc: 0.9603 - val_loss: 1.4390 - val_acc: 0.3684\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.1503 - acc: 0.9564 - val_loss: 1.6079 - val_acc: 0.3333\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1634 - acc: 0.9516 - val_loss: 1.5526 - val_acc: 0.3509\n"
     ]
    }
   ],
   "source": [
    "run_logdir =\"/home/ak47/AI_proj/logs\"\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir, update_freq='batch')\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5f435c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step - loss: 1.4726 - acc: 0.4655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4725784063339233, 0.4655172526836395]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f6f233d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'spr_model.h5'\n",
    "if train_model:\n",
    "    model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ffad7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.string>\n",
      "tf.Tensor(b'/home/ak47/Downloads/test1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'/home/ak47/Downloads/check.wav', shape=(), dtype=string)\n",
      "['Denny' 'Denny']\n",
      "[[5.9425294e-02 4.9024072e-01 2.3539840e-01 1.0240349e-01 8.5406855e-02\n",
      "  2.3742127e-03 1.3237508e-03 1.3275164e-02 1.0152159e-02]\n",
      " [1.7299768e-02 4.6901873e-01 3.7549508e-01 1.0517548e-02 1.1793719e-01\n",
      "  1.5947690e-04 2.3788540e-04 3.6584647e-04 8.9685135e-03]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_file=[\"/home/ak47/Downloads/test1.wav\",\"/home/ak47/Downloads/check.wav\"]\n",
    "\n",
    "\n",
    "sample_ds = tf.data.Dataset.from_tensor_slices(sample_file)\n",
    "print(sample_ds)\n",
    "\n",
    "mfcc_f=[]\n",
    "for i in sample_ds:\n",
    "    print(i)\n",
    "    file_name = bytes.decode(i.numpy())\n",
    "\n",
    "    wave, sample_rate = librosa.load(file_name, mono=True, sr=None)\n",
    "    \n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(wave, sample_rate)\n",
    "    mfcc = mfcc[:, :196]\n",
    "    pad_width = 196 - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    mfcc = tf.convert_to_tensor(mfcc)\n",
    "    mfcc = tf.expand_dims(mfcc, 2)\n",
    "    mfcc_f.append(mfcc)\n",
    "sample_input=tf.data.Dataset.from_tensor_slices(mfcc_f)    \n",
    "sample_input=sample_input.batch(2)\n",
    "\n",
    "\n",
    "output = model.predict(sample_input)\n",
    "\n",
    "speaker_ids = output.argmax(axis=1)\n",
    "speakers = speaker_encoder.inverse_transform(speaker_ids)\n",
    "print(speakers)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11117420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
